{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Case Study: Home Depot, Lowes, Tool Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "##### In this case study, we will be put in the shoes of a consultant looking to understand some of the factors that Lowe's and Home Depot look to when deciding to build new stores. We will then use this strategy to advise a new competitor we will call 'Tool Time' on where this new entrant should build its next five stores based on this information on Home Depot and Lowe's.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study Outline \n",
    "\n",
    "1. **Exploratory Data Analysis & creating a map of stores**\n",
    "1. **Identifying relationships between variables with linear regression model**\n",
    "1. **Leveraging linear regression model to perform _new store location predictions_ for Lowe's, Home Depot and Tool Time**\n",
    "1. **Comparing our results to realtor.com 'market hotness' data** \n",
    "\n",
    "\n",
    "## Questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cd'ing to the data directory and viewing available data files \n",
    "%cd ./data/\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdlo = pd.read_csv(\"Home_Depot_Lowes_Data.csv\", sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Perform Exploratory Data Analysis on the stores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a. What are the total store counts of Home Depot and Lowes?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('There are a total of {} Lowe\\'s stores in this dataset'.format(np.sum(hdlo.Lcount)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are a total of {} HDSupply stores in this dataset'.format(np.sum(hdlo.HDcount)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b. Create one dummy variable for Home Depot and one dummy variable for Lowes that identifies if the store is located in a county**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdlo['HD_dummy'] = (hdlo['HDcount'] > 0) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdlo['Lo_dummy'] = (hdlo['Lcount'] > 0) * 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c. Which store is present in more counties?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Lowe\\'s stores are present in {} counties'.format(np.sum(hdlo.Lo_dummy)))\n",
    "print('HDSupply stores are present in {} counties'.format(np.sum(hdlo.HD_dummy)))\n",
    "print('HDSupply have a presence in a higher number of counties than do Lowe\\'s stores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Use a United States map with FIPS locations to plot the store locations of both Lowes and Home Depot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.choropleth(hdlo, geojson=counties, locations='county', color='HDcount',\n",
    "                           color_continuous_scale=\"Viridis\",\n",
    "                           range_color=(0, 48),\n",
    "                           scope=\"usa\",\n",
    "                           labels={'HDcount':'Home Depot stores'},\n",
    "                           title = 'Home Depot Stores in the United States')\n",
    "fig.update_layout(margin={\"r\":0,\"t\":50,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.choropleth(hdlo, geojson=counties, locations='county', color='Lcount',\n",
    "                           color_continuous_scale=\"Viridis\",\n",
    "                           range_color=(0, hdlo.Lcount.max()),\n",
    "                           scope=\"usa\",\n",
    "                           labels={'Lcount':'Lowe\\'s stores'},\n",
    "                           title = 'Lowe\\'s Stores in the United States')\n",
    "fig.update_layout(margin={\"r\":0,\"t\":50,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a. What observations can you make from the map?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There tend to be high concentrations of Lowe's and Home Depot stores in metropolis and other high density areas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Create a linear regression model to identify the correlations among the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputing our data\n",
    "hdlo['pct_U18_2000'].fillna(hdlo.pct_U18_2000.mean(), inplace = True)\n",
    "hdlo['pct_U18_2010'].fillna(hdlo.pct_U18_2000.mean(), inplace = True)\n",
    "hdlo['pctwhite_2000'].fillna(hdlo.pct_U18_2000.mean(), inplace = True)\n",
    "hdlo['pctwhite_2010'].fillna(hdlo.pct_U18_2000.mean(), inplace = True)\n",
    "hdlo['pctblack_2000'].fillna(hdlo.pct_U18_2000.mean(), inplace = True)\n",
    "hdlo['pctblack_2010'].fillna(hdlo.pct_U18_2000.mean(), inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#further cleaning and separating our data \n",
    "hd_target = hdlo.HDcount\n",
    "lo_target = hdlo.Lcount\n",
    "hd_data = hdlo.copy()\n",
    "lo_data = hdlo.copy()\n",
    "hd_data.drop(['areaname','county','state','r1', 'r2', 'HD_dummy', 'Lo_dummy','HDcount','Lcount'], axis = 1, inplace = True)\n",
    "lo_data.drop(['areaname','county','state','r1', 'r2', 'HD_dummy', 'Lo_dummy','HDcount','Lcount'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting our linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr1 = LinearRegression(normalize=True).fit(hd_data, hd_target)\n",
    "print('Home Depot Regression Coefficients are:', lr1.coef_)\n",
    "lr2 = LinearRegression(normalize=True).fit(lo_data, lo_target)\n",
    "print('Lowe\\'s Regression Coefficients are:', lr1.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('R^2 of Home Depot regression is',lr1.score(hd_data, hd_target))\n",
    "print('R^2 of Lowes regression is',lr1.score(lo_data, lo_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "print(cross_val_score(lr1, hd_data, hd_target, cv = 5, n_jobs = -1))\n",
    "print(cross_val_score(lr2, lo_data, lo_target, cv = 5, n_jobs = -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a. What customer demographic variables are most import to Lowes?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd_scores = list(zip(hd_data.columns, lr1.coef_))\n",
    "lo_scores = list(zip(lo_data.columns, lr2.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(lo_scores, key = lambda x: x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lowe's is most interested in building new stores in areas where a large portion of the population is under the age of 18. This may be due to the fact that this may be an indicator that this county has high amounts of young families looking to potentially invest more down the road in home improvement. Lowe's is also interested in areas with high racial diversity and high rates of college education "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b. What customer demographic variables are most import to Home Depot?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(hd_scores, key = lambda x: x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Home Depot is most interested in building new stores in areas with high degrees of racial diversity. Interestingly, Home Depot actually builds less stores all else equal in areas with large amounts of the population that is under 18 years old, in contract to Lowe's which chooses to build more houses in areas with more <18yo people as a percentage of the population all else equal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c. How are the chains similar in their decision making?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As percent white and percent black variables appear in the top three variables of each regression analysis, it appears both chains place a heavy emphasis on areas with high degrees of racial diversity. Additionally, with pct_U18 and pctcollege appearing in the top five variables for each, counties with relatively higher amounts of young children, perhaps an indicator of families looking to further extend / renovate their homes, and relatively higher amounts of college educated people, perhaps an indicator of higher income households, also seem to be targets for new store construction for each chain. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d. How are they different?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Home Depot values home owners percentage in 2000 higher than Lowes. In addition, Lowes seems to value 2000 density more than Home Depot. It's interesting that both chains values the 2000 demographic statistics over the 2010 data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4:\tWhat are the top 5 towns / cities that can be predicted as potential candidates for new locations for both Lowes and Home Depot? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First way of answering this question - using the predict method of the LinearRegression class \n",
    "#to output how many stores in each area should be built, and returning the areas where \n",
    "#the most stores should be built according to our model \n",
    "\n",
    "nohd = hdlo.loc[hdlo['HDcount'] == 0]\n",
    "nohd.drop(['areaname','county','state','r1', 'r2', 'HD_dummy', 'Lo_dummy','HDcount','Lcount'], axis = 1, inplace = True)\n",
    "answers = zip(hdlo.loc[hdlo['HDcount'] == 0]['areaname'], list(lr1.predict(nohd)))\n",
    "sorted(answers, key = lambda x: x[1], reverse = True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nolo = hdlo.loc[hdlo['Lcount'] == 0]\n",
    "nolo.drop(['areaname','county','state','r1', 'r2', 'HD_dummy', 'Lo_dummy','HDcount','Lcount'], axis = 1, inplace = True)\n",
    "answers = zip(hdlo.loc[hdlo['Lcount'] == 0]['areaname'], list(lr2.predict(nolo)))\n",
    "sorted(answers, key = lambda x: x[1], reverse = True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second way of answering this question - building Logistic Regression models that predict 1 = area where store \n",
    "#should be built and 0 = area where store should not be built (differs from Linear Regression prediction in that \n",
    "#you are instead predicting whether an area should have a store built, instead of how many stores should be built there)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#preparing our data \n",
    "hd_x = hdlo.copy()\n",
    "hd_y = hdlo.HD_dummy\n",
    "lo_x = hdlo.copy()\n",
    "lo_y = hdlo.Lo_dummy\n",
    "hd_x.drop(['areaname','county','state','r1', 'r2', 'HD_dummy', 'Lo_dummy','HDcount','Lcount'], axis = 1, inplace = True)\n",
    "lo_x.drop(['areaname','county','state','r1', 'r2', 'HD_dummy', 'Lo_dummy','HDcount','Lcount'], axis = 1, inplace = True)\n",
    "\n",
    "hdxtrain, hdxtest, hdytrain, hdytest = train_test_split(hd_x, hd_y, test_size = 0.3)\n",
    "loxtrain, loxtest, loytrain, loytest = train_test_split(lo_x, lo_y, test_size = 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training our models \n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "lg1 = LogisticRegressionCV(Cs=10, cv=5, class_weight='balanced', max_iter=100, random_state=24)\n",
    "lg2 = LogisticRegressionCV(Cs=10, cv=5, class_weight='balanced', max_iter=100, random_state=24)\n",
    "lg1.fit(hdxtrain, hdytrain)\n",
    "lg2.fit(loxtrain, loytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict our test data using these fitted models \n",
    "lg1.score(hdxtest, hdytest)\n",
    "lg2.score(loytest, loytest)\n",
    "#since these scores are rather good we can go ahead with training on our full data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg3 = LogisticRegressionCV(Cs=10, cv=5, class_weight='balanced', max_iter=100, random_state=24)\n",
    "lg4 = LogisticRegressionCV(Cs=10, cv=5, class_weight='balanced', max_iter=100, random_state=24)\n",
    "lg3.fit(hd_x, hd_y)\n",
    "lg4.fit(lo_x, lo_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding predicted probabilities to our dataframes to show areas with highest predicted store presence in areas where \n",
    "# store count = 0 \n",
    "hd_x2 = hd_x.assign(HD_dummy = hdlo.HD_dummy)\n",
    "hd_x2 = hd_x2.assign(areaname = hdlo.areaname)\n",
    "hd_x2 = hd_x2.loc[hd_x2['HD_dummy'] == 0]\n",
    "hd_x2areaname = hd_x2.areaname\n",
    "hd_x2.drop(['HD_dummy','areaname'], axis = 1, inplace = True)\n",
    "hd_predictions = [x[1] for x in lg1.predict_proba_(hd_x2)]\n",
    "hdanswers = list(zip(hd_x2areaname, list(hd_predictions)))\n",
    "sorted(hdanswers, key = lambda x: x[1])[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doing same for Lowes\n",
    "lo_x2 = lo_x.assign(Lo_dummy = hdlo.Lo_dummy)\n",
    "lo_x2 = lo_x2.assign(areaname = hdlo.areaname)\n",
    "lo_x2 = lo_x2.loc[lo_x2['Lo_dummy'] == 0]\n",
    "lo_x2areaname = lo_x2.areaname\n",
    "hd_x2.drop(['Lo_dummy','areaname'], axis = 1, inplace = True)\n",
    "lopredictions = [x[1] for x in lg4.predict_proba_(lo_x2)]\n",
    "zippedanswer = list(zip(lo_x2areaname, list(lopredictions)))\n",
    "sorted(zippedanswer, key = lambda x: x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5. Where should “Tool Time” build its next 5 stores based on the Census Data on your customers? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression model predicts that Pinal, AZ; Ramsey, MN; Weld, CO; Webb, TX; and Ingham, MI are the top 5 locations to build new Tool Time stores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a. Explain your rational for your decision**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to find locations where both Home Depot and Lowes would consider building new stores, but we don't want to build in an area that is already saturated with other chains' stores. For this reason, I filtered the data by locations that had 1 or no stores for both chains. Then I sorted by probability that the location is a good place to build a store. This gives us locations that are promising for building stores, but have low stauration in terms of competition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6. realtor.com market hotness index report "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a. Using the realtor.com market hotness index report from August of 2018 create an additional variable to segment the country into the following regions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only relevant columns from state_region\n",
    "state_region = pd.read_csv('state_region.csv', sep = ',')\n",
    "state_region.drop(['State', 'Division'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in our data\n",
    "rdc = pd.read_csv('RDC_MarketHotness_Monthly.csv', sep = ',')\n",
    "rdc['town'], rdc['state'] = rdc['ZipName'].str.split(',').str[0], rdc['ZipName'].str.split(', ').str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = rdc.merge(state_region, how = 'left', left_on = 'state', right_on = 'State Code')\n",
    "df1.drop('State Code', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 36)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b. Exploratory Data Analysis for realator.com data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**i. Which Region of the country has the best “Demand Score”**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.groupby('Region')['Demand Score'].mean()\n",
    "#The Northeast has the best mean demand score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii. Which State in the country has the best “Demand Score”**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.groupby('state')['Demand Score'].aggregate({'mean'}).sort_values(by = 'mean', ascending = False)[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Massachusetts has the best mean \"Demand Score.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**iii. Which metro area (pop_2010 > 1million) has the best “Demand Score”**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging our data from hdlo to extract population for each country\n",
    "hdlo2 = hdlo[['county','pop_2010']]\n",
    "df2 = df1.merge(hdlo2, how = 'inner', left_on = 'CountyFIPS', right_on = 'county')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[df2.pop_2010 > 1e6][['CountyName', 'state','Demand Score']][:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Middlesex, MA has the best \"Demand Score\" of metro areas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c.\tCompare and contrast these findings with your predicted new store findings.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**i. Describe your findings as they relate to the customer attributes and potential business opportunity that Lowes, Home Depot and/or Tool Time may have if they are or are not located in the areas that have high demands for real estate opportunities**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the Northeast, Texas, Ohio, California, and Florida are all good areas for stores to be loacted, according to \"Demand Score.\" This somewhat agrees with the model predictions; there were a lot of predicted locations in California and the Northeast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d. Add the following as features to the original HDLo data set and predict again where Tool Time should build its next 5 stores.**\n",
    "1.\tMedian.Listing.Price\n",
    "2.\tDemand.Score\n",
    "3.\tHotness.Score\n",
    "4.\tNieleson.HH.Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdc2 = rdc[['CountyFIPS','Nielsen HH Rank','Demand Score','Hotness Score','Median Listing Price']]\n",
    "hd_data = hdlo.merge(rdc2, how = 'inner', left_on = 'county', right_on = 'CountyFIPS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy data into training and testing sets, drop earlier added probability columns along with other irrelevant columns\n",
    "hd_data = hd_data.copy()\n",
    "l_data = hd_data.copy()\n",
    "\n",
    "hd_data.drop(['areaname', 'county', 'state', 'r1', 'r2', 'Lcount', 'HDcount', 'Lexists'], axis=1, inplace=True)\n",
    "l_data.drop(['areaname', 'county', 'state', 'r1', 'r2', 'Lcount', 'HDcount', 'HDexists'], axis=1, inplace=True)\n",
    "\n",
    "hd_X = hd_data.drop(['HD_dummy'], axis=1)\n",
    "hd_y = hd_data.HD_dummy\n",
    "\n",
    "l_X = l_data.drop(['Lo_dumm7'], axis=1)\n",
    "l_y = l_data.Lo_dummy\n",
    "\n",
    "# Split the data into train and test portions to test accuracy\n",
    "hd_X_train, hd_X_test, hd_y_train, hd_y_test = train_test_split(hd_X, hd_y, random_state=42)\n",
    "l_X_train, l_X_test, l_y_train, l_y_test = train_test_split(l_X, l_y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the models\n",
    "hd_logit = LogisticRegressionCV(Cs=10, cv=5, class_weight='balanced', max_iter=1000, random_state=42).fit(hd_X_train, hd_y_train)\n",
    "l_logit = LogisticRegressionCV(Cs=10, cv=5, class_weight='balanced', max_iter=1000, random_state=42).fit(l_X_train, l_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Home Depot store predicition accuracy\n",
    "hd_logit.score(hd_X_test, hd_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowes store predicition accuracy\n",
    "l_logit.score(l_X_test, l_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on the full data\n",
    "hd_full_logit = LogisticRegressionCV(Cs=10, cv=5, class_weight='balanced', max_iter=1500, random_state=42).fit(hd_X, hd_y)\n",
    "l_full_logit = LogisticRegressionCV(Cs=10, cv=5, class_weight='balanced', max_iter=1500, random_state=42).fit(l_X, l_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the target for all locations and extract the probability that a store should be built\n",
    "hd_store_prob = [x[1] for x in hd_full_logit.predict_proba(hd_X)]\n",
    "l_store_prob = [x[1] for x in l_full_logit.predict_proba(l_X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the probability features to the original dataset so we can find the best next locations to build stores\n",
    "added_data['hd_store_prob'] = hd_store_prob\n",
    "added_data['l_store_prob'] = l_store_prob\n",
    "\n",
    "# Create new column that is the sum of the two probability columns for sorting purposes\n",
    "added_data['prob_sum'] = added_data.hd_store_prob + added_data.l_store_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For Tool Time, show only locations where there are 1 or no stores for HD and Lowes,\n",
    "# sort by prob_sum descending and show top 5 areas predicted to be the best store locations\n",
    "added_data[(added_data.Lcount <= 1) & (added_data.HDcount <= 1)].sort_values(by='prob_sum', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e. What are the top 5 new area names for which Tool Time should build their stores?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first four stores remain the same, however Ottawa, MI overtook Ingham, MI in this version of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f. Do these features increase the prediction accuracy for the new area predictions?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the new scores, the new features seem to have decreased the accuracy of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**g. Does overlaying the realtor data set add value to the business strategy of Tool Time?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, I would conclude that adding the new features **does not** add value to the business strategy that I would recommend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**h. Is there an alternative strategy that Tool Time should explore other than Census Data and Realtor data?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tool Time might want to consider areas that have high demand for commerical real estate, as new businesses will have contractors in need of supplies. Tool Time might also want to look into trends for up-and-coming neighborhoods where real estate prices may increase in the future, and get ahead of competitors by opening stores newly desired neighborhoods."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
